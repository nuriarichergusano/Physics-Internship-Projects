{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e90170",
   "metadata": {},
   "source": [
    "Objetive of the project could be finding a regularisation of the latent space to extract high-level features of the signals obtained from the Sauron Semiconductors placed inside the AGATA.\n",
    "\n",
    "Things to do:\n",
    "-Solve errors of Calibration_modified.py.\n",
    "-Find regularisation strategies from the book ML for Physicist in this unsupervised autoencoder.\n",
    "-Add .root dataset of Daniele Mengoni to the code.\n",
    "-Improve the noise reduction by including other techniques to the dataset (e.g. cross-validation).\n",
    "-Add axis units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61f5878a-f63d-4176-95bc-635d4dd1f85d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/luna/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PIDDataset, skipping build step...\n",
      "Loading extension module PIDDataset...\n"
     ]
    }
   ],
   "source": [
    "#Loading the libraries and compiling the c++ module\n",
    "\n",
    "from torch.utils.cpp_extension import load\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "#import seaborn as sn\n",
    "import os\n",
    "import glob\n",
    "import lightning\n",
    "import matplotlib\n",
    "import math\n",
    "import torchmetrics\n",
    "import pytorch_model_summary as pms\n",
    "\n",
    "\n",
    "#from autoencoder import *\n",
    "\n",
    "#Compile the c++ module\n",
    "pid_dataset = load(name=\"PIDDataset\",\n",
    "                   sources=[\"PidDataset.cpp\",\"ReadRawData.cpp\",\"ReadBinaryData.cpp\", \"mwdlib.cpp\"],\n",
    "                   verbose=True,\n",
    "                   extra_cflags=['-O3'],\n",
    "                  )\n",
    "\n",
    "# TO SHOW INTERACTIVE PLOT\n",
    "%matplotlib widget\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dacbaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define NN parameters\n",
    "\n",
    "\n",
    "derivative_order=1\n",
    "normalized=False\n",
    "convolutional=False #I can try to put this to False!!!\n",
    "dropout_p=0.0 #In big NN we can put this parameter to 50% to avoid overfitting, by eliminating neurons. In this case, a smaller NN, it is not that useful.\n",
    "#nLayers_list = [20, 30, 40, 50]\n",
    "#nLayers_list = [4,6,8,10, 20, 60, 100]\n",
    "nLayers_list=[4]\n",
    "#act_fn = torch.nn.ReLU\n",
    "kernel_size = 6\n",
    "stride = 2\n",
    "act_fn = torch.nn.GELU #Activation function\n",
    "#pooling_kernel_size = 2\n",
    "\n",
    "#Training parameters\n",
    "batch_size = 150 #1000 was working. \n",
    "learning_rate = 3e-3 #If it's too big, it may go out of the gradient descent.\n",
    "#batch_size = 5000 #this only makes things slow\n",
    "retrain=True #??\n",
    "version_nr = 0\n",
    "EarlyStoppingNr = 10 #15 was working.\n",
    "max_epochs = 100 #before we had 300.\n",
    "exclude_outliers = False\n",
    "hidden_size = 128  # Número de neuronas en cada capa oculta de la LSTM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Dataset\n",
    "dataset = \"Fazia\"\n",
    "\n",
    "if dataset == \"Sauron\":\n",
    "    trainDatasetFile = \"./DataFusEvSauron/RU_caendig_i1468_0005_0000.caendat\"\n",
    "    datasetEvents = 3_000_000 #Events=Number of total signals.\n",
    "    samples_number=128\n",
    "    first_sample=0\n",
    "    n_channels=64\n",
    "elif dataset == \"Oscar\":\n",
    "    trainDatasetFile = \"./DataLiFOscar/data_0-7.caendat\"\n",
    "    datasetEvents = 709_755\n",
    "    samples_number=40\n",
    "    first_sample=200\n",
    "    n_channels=16\n",
    "elif dataset == \"Fazia\":\n",
    "    trainDatasetFile = \"./Fazia/Signal_and_IdCal_221.dat\"\n",
    "    datasetEvents = 709_756\n",
    "    samples_number=30\n",
    "    first_sample=10\n",
    "    n_channels=25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb40f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMNet(lightning.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, act_fn, num_classes, dropout_p=0.5, class_weights=None):\n",
    "        super().__init__()\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        if class_weights is not None:\n",
    "            self.criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        else:\n",
    "            self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Definir la red LSTM\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_p)\n",
    "\n",
    "        # Fully connected layer para la salida\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "    # Supongamos que x tiene las dimensiones (batch_size, sequence_length, channels, input_size)\n",
    "        if len(x.shape) == 4:\n",
    "            batch_size, sequence_length, channels, input_size = x.shape\n",
    "            # Aplanar las dimensiones de 'channels' y 'input_size' para que sea compatible con LSTM\n",
    "            x = x.view(batch_size, sequence_length, channels * input_size)\n",
    "\n",
    "        # Inicializar los estados ocultos y de celda\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Pasar por la capa LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Usar la salida de la última secuencia temporal\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "    def _get_reconstruction_loss(self, batch):\n",
    "        x, y = batch\n",
    "        x_hat = self.forward(x)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.2, patience=3, min_lr=5e-7)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        acc = self.accuracy(x_hat, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        acc = self.accuracy(x_hat, y)\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True)\n",
    "        return {'val_loss': loss, 'val_acc': acc, 'preds': x_hat, 'targets': y}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        acc = self.accuracy(x_hat, y)\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('test_acc', acc, on_step=False, on_epoch=True)\n",
    "        return {'test_loss': loss, 'test_acc': acc, 'preds': x_hat, 'targets': y}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f005f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "\n",
    "\n",
    "split_percent = [0.8, 0.1, 0.1] #90% for training, 5% for testing and 5% for validating.\n",
    "\n",
    "[train_dataset, val_dataset, test_dataset] = torch.utils.data.random_split(\n",
    "                pid_dataset.PIDDataset(root=trainDatasetFile, \n",
    "                                       mode=pid_dataset.kTrain, \n",
    "                                       count=datasetEvents, \n",
    "                                       nder=derivative_order, \n",
    "                                       nsamples=samples_number, \n",
    "                                       firstsample=first_sample,\n",
    "                                       nchannels=n_channels,\n",
    "                                       normalized=normalized,\n",
    "                                       discardenergies=False,\n",
    "                                       minenergy=0,\n",
    "                                       maxenergy=100,),\n",
    "                                       split_percent)\n",
    "\n",
    "#Sampler to normalize the amount of types of each class\n",
    "weights = torch.zeros(len(train_dataset))\n",
    "class_counts = torch.zeros(n_channels)\n",
    "\n",
    "#cont the occurrence of each class in the dataset\n",
    "for i in range(len(train_dataset)):\n",
    "    class_counts[train_dataset[i][1]] += 1\n",
    "\n",
    "#calculate the weights\n",
    "for i in range(len(train_dataset)):\n",
    "    weights[i] = class_counts[train_dataset[i][1]]\n",
    "    \n",
    "weights = 1.0 / weights\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "sampler = torch.utils.data.WeightedRandomSampler(weights=weights, num_samples=len(train_dataset), replacement=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           #shuffle=True, \n",
    "                                           drop_last=True, \n",
    "                                           pin_memory=True, \n",
    "                                           num_workers=4,\n",
    "                                           sampler=sampler)\n",
    "#Batch size: number of signals per batch.\n",
    "#Shuffle: shuffle data at every epoch.\n",
    "#Epoch: During an epoch, the model processes each training example once, \n",
    "#and the learning process updates the model's parameters based on the loss calculated from the training examples.\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                         batch_size=2_000, \n",
    "                                         shuffle=False, \n",
    "                                         drop_last=False, \n",
    "                                         num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=2_000, \n",
    "                                          shuffle=False, \n",
    "                                          drop_last=False, \n",
    "                                          num_workers=4)\n",
    "\n",
    "def get_train_images(num):\n",
    "    #return [torch.stack([train_dataset[i][0] for i in range(num)], dim=0), torch.stack([train_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([train_dataset[i][0] for i in range(num)], dim=0)\n",
    "    #Here i is the batch and what is 0? dim=0 is the dimension of the output tensor.\n",
    "    #What are IDs???\n",
    "\n",
    "def get_train_labels(num):\n",
    "    #return [torch.stack([train_dataset[i][0] for i in range(num)], dim=0), torch.stack([train_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([train_dataset[i][1] for i in range(num)], dim=0)\n",
    "    #Here i is the batch and what is 0? dim=0 is the dimension of the output tensor.\n",
    "    #What are IDs???\n",
    "\n",
    "def get_validation_images(num):\n",
    "    #return [torch.stack([val_dataset[i][0] for i in range(num)], dim=0), torch.stack([val_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([val_dataset[i][0] for i in range(num)], dim=0)\n",
    "\n",
    "def get_validation_labels(num):\n",
    "    #return [torch.stack([val_dataset[i][0] for i in range(num)], dim=0), torch.stack([val_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([val_dataset[i][1] for i in range(num)], dim=0)\n",
    "    \n",
    "def get_test_images(num):\n",
    "    #return [torch.stack([test_dataset[i][0] for i in range(num)], dim=0), torch.stack([test_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([test_dataset[i][0] for i in range(num)], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd3aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "      Layer (type)                              Output Shape         Param #     Tr. Param #\n",
      "=============================================================================================\n",
      "            LSTM-1     [4, 1, 128], [4, 4, 128], [4, 4, 128]         478,720         478,720\n",
      "          Linear-2                                   [4, 25]           3,225           3,225\n",
      "=============================================================================================\n",
      "Total params: 481,945\n",
      "Trainable params: 481,945\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Debug cell???\n",
    "\n",
    "# Supongamos que nLayers_list es una lista de tamaños para las capas ocultas\n",
    "for nLayers in nLayers_list:\n",
    "    input_size = derivative_order * samples_number + 1 # Ajusta esto de acuerdo a tus datos de entrada\n",
    "\n",
    "    # Crea la red totalmente conectada con el tamaño de las capas ocultas basadas en nLayers\n",
    "    test = LSTMNet(input_size=input_size, \n",
    "               num_classes=n_channels, \n",
    "               hidden_size=hidden_size,  # Tamaño de la capa oculta\n",
    "               num_layers=nLayers,  # Número de capas LSTM\n",
    "               act_fn=nn.GELU, \n",
    "               dropout_p=0.5, \n",
    "               class_weights=None)\n",
    "   \n",
    "\n",
    "    x = test(get_train_images(4))  # x es la salida de la red\n",
    "    print(pms.summary(test, get_train_images(4)))  # Resumen de la arquitectura\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback functions\n",
    "\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/classifier\")\n",
    "\n",
    "class ConfusionMatrixCallback(lightning.pytorch.callbacks.Callback):\n",
    "    def __init__(self, input, labels, every_n_epochs=1, data_type=\"train\"):\n",
    "        super().__init__()# It's often used to call the parent class's __init__ method to ensure that the parent class is properly initialized when creating an instance of the derived class.\n",
    "        # Only save uthose images every N epochs (otherwise tensorboard gets quite large)\n",
    "        self.every_n_epochs = every_n_epochs\n",
    "        self.input = input\n",
    "        self.labels = labels\n",
    "        self.data_type = data_type\n",
    "\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        signals = self.input.to(pl_module.device)\n",
    "        with torch.no_grad():\n",
    "            pl_module.eval()\n",
    "            print(signals.shape)\n",
    "            output = pl_module(signals)\n",
    "            pl_module.train()\n",
    "\n",
    "        #calculate te confusion matrix\n",
    "        cm = torchmetrics.ConfusionMatrix(num_classes=pl_module.num_classes, task='multiclass')\n",
    "        cm.update(output, self.labels)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "        cm = cm.compute().numpy()\n",
    "        cax = ax.matshow(cm, cmap='Blues')\n",
    "        plt.colorbar(cax)\n",
    "        for (i, j), val in np.ndenumerate(cm):\n",
    "            ax.text(j, i, f'{val}', ha='center', va='center', color='black')\n",
    "\n",
    "        #ax.imshow(cm.compute().numpy(), cmap='hot', interpolation='nearest')\n",
    "        ax.set_title('Confusion matrix')\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('True')\n",
    "        if self.data_type == \"train\":\n",
    "            trainer.logger.experiment.add_figure(\"Confusion Matrix Train\", fig, global_step=trainer.global_step)\n",
    "        elif self.data_type == \"validation\":\n",
    "            trainer.logger.experiment.add_figure(\"Confusion Matrix Validation\", fig, global_step=trainer.global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training function definition\n",
    "\n",
    "def train(base_channel_size, retrain=False):\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "\n",
    "    netName = \"model_bc%i_do%i\" % (base_channel_size, derivative_order)\n",
    "    \n",
    "    callbacks=[\n",
    "        #lightning.pytorch.callbacks.ModelCheckpoint(save_weights_only=True),\n",
    "        #ImageCallback(every_n_epochs=1),\n",
    "        ConfusionMatrixCallback(input=get_train_images(40_000), labels=get_train_labels(40_000), every_n_epochs=1, data_type=\"train\"),\n",
    "        ConfusionMatrixCallback(input=get_validation_images(10_000), labels=get_validation_labels(10_000), every_n_epochs=1, data_type=\"validation\"),\n",
    "        lightning.pytorch.callbacks.LearningRateMonitor(\"epoch\"),\n",
    "        lightning.pytorch.callbacks.ModelCheckpoint(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_top_k=1,  # Save only the best checkpoint based on validation loss\n",
    "            save_last=True,  # Save the latest checkpoint\n",
    "            filename='{epoch}-{val_loss:.2f}',  # Customize the filename with epoch and validation loss\n",
    "            verbose=True,\n",
    "        ),\n",
    "        lightning.pytorch.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=EarlyStoppingNr,\n",
    "            verbose=False,\n",
    "            min_delta=0.00,\n",
    "        ),\n",
    "        # Other callbacks...\n",
    "    ]\n",
    "\n",
    "    trainer = lightning.Trainer(\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, netName),\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        callbacks=callbacks,\n",
    "        max_epochs=max_epochs,\n",
    "        logger=lightning.pytorch.loggers.tensorboard.TensorBoardLogger(\"saved_models/classifier\", \n",
    "                                                                       name=netName),\n",
    "    )\n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    #ckpt_files = glob.glob('saved_models/autoencoder/%s/version_0/checkpoints/epoch*.ckpt' % (netName))\n",
    "    ckpt_files = glob.glob('saved_models/classifier/%s/version_%i/checkpoints/epoch*.ckpt' % (netName, version_nr))\n",
    "\n",
    "    if ckpt_files and not retrain:\n",
    "        print(\"Found pretrained model, called %s\" % ckpt_files[0])\n",
    "        model = LSTMNet.load_from_checkpoint(ckpt_files[0])\n",
    "        #model.to(\"cuda\")\n",
    "        model.to(\"cpu\")\n",
    "    else:   \n",
    "        #ids_nr = get_test_images(1)[1].shape[1] - 1 \n",
    "       # Dentro de la función train, cambia la siguiente línea\n",
    "        model = LSTMNet(input_size=input_size,  \n",
    "                num_classes=n_channels,\n",
    "                hidden_size=hidden_size,  # Aquí puedes definir el tamaño de las capas ocultas\n",
    "                num_layers=nlayers,  # Esto ajusta el número de capas\n",
    "                act_fn=act_fn, \n",
    "                dropout_p=dropout_p,\n",
    "                class_weights=None)\n",
    "\n",
    "                        \n",
    "        print(\"testing on a single batch...\")\n",
    "        print(\"inished testing on a single batch...\")\n",
    "\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "        print(\"Finished training, saving model...\")\n",
    "\n",
    "        # Test best model on validation and test set\n",
    "        val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n",
    "        test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "        result = {\"test\": test_result, \"val\": val_result}\n",
    "        return model, result\n",
    "        print(\"Finished training, saving model...\")\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "    result = {\"test\": test_result, \"val\": val_result}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b155217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luna/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | accuracy  | MulticlassAccuracy | 0     \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | lstm      | LSTM               | 478 K \n",
      "3 | fc        | Linear             | 3.2 K \n",
      "-------------------------------------------------\n",
      "481 K     Trainable params\n",
      "0         Non-trainable params\n",
      "481 K     Total params\n",
      "1.928     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on a single batch...\n",
      "inished testing on a single batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luna/miniconda3/envs/pytorch/lib/python3.11/site-packages/lightning/pytorch/loggers/tensorboard.py:187: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f89bdef3d640d086c44c5fc02748c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bf7971807045f090917efd2f2d52be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3702ca0021094b81ad1fbfaec2c7fde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3785: 'val_loss' reached 0.58596 (best 0.58596), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=0-val_loss=0.59.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2161b47119794c01a720e282b120d562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 7570: 'val_loss' reached 0.45588 (best 0.45588), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=1-val_loss=0.46.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b40fd24a77a424596c0cf3772407cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 11355: 'val_loss' reached 0.44943 (best 0.44943), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=2-val_loss=0.45.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6c30ab9931473a983f617f8d138ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 15140: 'val_loss' reached 0.40059 (best 0.40059), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=3-val_loss=0.40.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e367708f7d4943af462d0f79432657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 18925: 'val_loss' reached 0.37490 (best 0.37490), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=4-val_loss=0.37.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028a217dc58e4f65be39a511b3e3161d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 22710: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079e8d326c6342e4a26a3a3deaf519fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 26495: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769bd07d42be48dea03c47798358f58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 30280: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7e41d13b904468af88366cfe105419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 34065: 'val_loss' reached 0.37217 (best 0.37217), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=8-val_loss=0.37.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5fc1a8959c4d919419549e66409931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 37850: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc01888a7cc64b7292f71f68997e434e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 41635: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e584cd41a4a44bb48f408125e8e2bb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 45420: 'val_loss' reached 0.35308 (best 0.35308), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=11-val_loss=0.35.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd7abf6966c4089bc786978609ac39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 49205: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f71b9711ed847f1a977930f581a0c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 52990: 'val_loss' reached 0.34488 (best 0.34488), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=13-val_loss=0.34.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a944ae01e7204d9091445b9a06f823ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 56775: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca9dda24f6442c68eb7c4ec901fc3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 60560: 'val_loss' reached 0.34176 (best 0.34176), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=15-val_loss=0.34.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f797b2e8554bf3b54295d9ae4d11f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 64345: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9464fb3c6cd942628369fad19db00b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 68130: 'val_loss' reached 0.33429 (best 0.33429), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=17-val_loss=0.33.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb44e8d398de4f378f991e5583eddcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 71915: 'val_loss' reached 0.31648 (best 0.31648), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=18-val_loss=0.32.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641d9427d34b486cbe96a0c0956e0992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 75700: 'val_loss' reached 0.31122 (best 0.31122), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=19-val_loss=0.31.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1ccad6666e4cc2bc12f6ac44e41285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 79485: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1adc0bd1db45089d14c71d65567470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 83270: 'val_loss' reached 0.27758 (best 0.27758), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=21-val_loss=0.28.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cb0051cb8b4657a3f5ca8516a29761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 87055: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a388499d4bd54299943d04aa7e6e4e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 90840: 'val_loss' reached 0.26449 (best 0.26449), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=23-val_loss=0.26.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6257ff08d66403fa54db0831d17440f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 94625: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d437a77b20404371a7148a02420e2e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 98410: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbf88f50c0a4b709ff69c65e7f99ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 102195: 'val_loss' reached 0.25253 (best 0.25253), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=26-val_loss=0.25.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899dd414217b4c5ab3d4f564886497a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 105980: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e4330ccfc84d00b878f2dddd19e07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 109765: 'val_loss' reached 0.25238 (best 0.25238), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=28-val_loss=0.25.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521c64ed3a8a46499cfcd4cdcf40accf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 113550: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e83a764e604ae6ade00039b1a41b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 117335: 'val_loss' reached 0.23699 (best 0.23699), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=30-val_loss=0.24.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9148f067d54ca7b7dc29d2be9499fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 121120: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f76dbd87bbe4b2c98aa5d64214c26c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 124905: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718fbca9df58485f9137f4be9866a2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 128690: 'val_loss' reached 0.23631 (best 0.23631), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=33-val_loss=0.24.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b26c24f7f2482eb1677edb61200fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 132475: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59969e40327f4af0aabd314e7822cca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, global step 136260: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b843796d25164221a5192607ed627331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, global step 140045: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262e24734e1f454dbd4fcd8c324d31da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 143830: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a51ec1a119f424eb7e4053aa612ce29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, global step 147615: 'val_loss' reached 0.21182 (best 0.21182), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=38-val_loss=0.21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379ede63e1e14bc0b112c5cff4d7ec80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 151400: 'val_loss' reached 0.20797 (best 0.20797), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=39-val_loss=0.21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd72bdfbd44244d3867bff46302cb2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 155185: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b86ad3a2c82483eb34abd816a422c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, global step 158970: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6689f1c92ef44f0baf2d657b6514cd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 162755: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bab29aada94844b618ebd2d5f4d834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 166540: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8da142b2a2494397b203f32b18f1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, global step 170325: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2570c69228c4aa6b6e51f83cc118fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, global step 174110: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dc74cac54f4330bcc72e71b79505c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46, global step 177895: 'val_loss' reached 0.20723 (best 0.20723), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=46-val_loss=0.21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a43a8ad5a7440b98eb928dbf4ba1a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, global step 181680: 'val_loss' reached 0.20717 (best 0.20717), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=47-val_loss=0.21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f31a1bd4b93454fb451a2913c50ae4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, global step 185465: 'val_loss' reached 0.20716 (best 0.20716), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=48-val_loss=0.21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8fa93e258444d5ba7c48a6e4599d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 189250: 'val_loss' reached 0.20711 (best 0.20711), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=49-val_loss=0.21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f410fdc2c3046cfbdc5a3884b79ce34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50, global step 193035: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5c4f06fd36462e9e5f1911449c02a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51, global step 196820: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8066fd8d710647bbb1a5eacb09bcf505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52, global step 200605: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62444186e6f24f22953f517f2510e986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53, global step 204390: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5582057f9f3c4fb59ba5796ca3e3f499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54, global step 208175: 'val_loss' reached 0.20666 (best 0.20666), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=54-val_loss=0.21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6671ce74120432da795050e2dcc5ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55, global step 211960: 'val_loss' reached 0.20577 (best 0.20577), saving model to 'saved_models/classifier/model_bc4_do1/version_6/checkpoints/epoch=55-val_loss=0.21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10182e712db84e0b8bd0dd43d90f7f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56, global step 215745: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48259ff8fcb64522ad0c291576ebdb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57, global step 219530: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74120ba5abd9403d8f0bd7862db5c5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58, global step 223315: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fe312c52ae4034b4bda98ad39a368f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 227100: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19deb8f1164d41d7817533aeef93472b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60, global step 230885: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f6e77a91eb420884b9771438befcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61, global step 234670: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5ad53beceb42b2b795bf7f68662800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62, global step 238455: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862714879f554c2388d587ef5b753b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63, global step 242240: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab02f1d6e304986887530e668a6fe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64, global step 246025: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac661fe6bcb44b64a51608c0bbede553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65, global step 249810: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training, saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019fc3e4a7404ec69c5f3ae6925995dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9551aa090bc247e0b0d2388398d21a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training loop\n",
    "colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\", \"orange\", \"purple\"]\n",
    "model_list= []\n",
    "for nlayers in nLayers_list:\n",
    "    model_ld, result_ld = train(nlayers, retrain=retrain)\n",
    "    model_list.append({\"nlayers\": nlayers,\n",
    "                       \"model\": model_ld, \n",
    "                       \"result\": result_ld, \n",
    "                       \"color\": colors.pop(0)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a2ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'latent_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Compare loss as a function of latent dimensionality\u001b[39;00m\n\u001b[1;32m      3\u001b[0m latent_dim\u001b[38;5;241m=\u001b[39mn_channels\n\u001b[0;32m----> 5\u001b[0m latent_dims \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatent_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m nlayers \u001b[38;5;241m=\u001b[39m [m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n\u001b[1;32m      7\u001b[0m val_scores \u001b[38;5;241m=\u001b[39m [m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Compare loss as a function of latent dimensionality\u001b[39;00m\n\u001b[1;32m      3\u001b[0m latent_dim\u001b[38;5;241m=\u001b[39mn_channels\n\u001b[0;32m----> 5\u001b[0m latent_dims \u001b[38;5;241m=\u001b[39m [\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatent_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n\u001b[1;32m      6\u001b[0m nlayers \u001b[38;5;241m=\u001b[39m [m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n\u001b[1;32m      7\u001b[0m val_scores \u001b[38;5;241m=\u001b[39m [m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'latent_dim'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: 636b9c8c87684d6b861ed8a6b9838099\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: bee4231bdca542f7bf01d57d0c1f5445\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f058648da1a4476abf7b657703191fd1\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: f50b609eb8d54e02a6af41c56b588c82\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: db2ad54e7abd4cd5bb8cb5022e18fbc2\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: 2f8c2d22fa4d4b37a8992f175898a864\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: ecac9f0a35374ba6bbfbd3ae8d5748ea\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 2dad612f70b64322b81f0d2b1f039cb6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 9e8ec5e86f834930b687b7aa7480e9a6\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: 66d6faa0c70846699369bda57827aa5d\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: dc550bad92bc4f4080f4b989bfafb7a0\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 76cf93c1631d4085a948eb987407bea8\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: 3921c7ef94e04880b7eb8a9ebdeb8625\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: fb6f2cb38dc1423f93c30b9cf1fb03fa\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 54102ff0f1ea4b85a322e6bfbebbef76\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: 6d6efe2364b24f68bc1186e9836657bb\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: f36214a5e04b4e0d9b14757cbdb51d8b\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: 4a0350eee5004721bd9e14e369797aed\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: c53b9285f6ed4a2c96e8803c89cb90e0\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: cbc98eecda3f41fdb2aa2a707d615a20\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: aa2151db14b1402aafa8e811a899a9f8\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 754d26d1276b4ac588edd3cd57d72e40\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: 0ea9f531b5b34d53948c28c327b4c5b8\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: a08771de061c43f49ed5f495a48300fc\n",
      "No such comm: f361e901b14d413bb75957cda9ddb01a\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 92557d920c5f4424955b282a566505a3\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 828840fe881f4059887d13d227b81917\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 746941028bac439e8946caf6033dae3c\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 37d2a5a5a194412986f449b27656ae0d\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: 5c013b785480403396cac10667d68086\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: dc039e80f0814956806abf3cf72cd5c8\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: 6d4a3724d3e248f585b3b445c957db51\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: bdb7cf56f7b54634a40e8a65d7aebbaf\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 6ba8662767cf4acfa7c4cf41f3689357\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 8dea815b2799495888880bca19a4a66d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 9e6f2d141d9f445b9f6f2a51ee021e4d\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 75d6f2c6dd194606b2f18593cb7fe03f\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 91e7cd72dbd7402ba1f434fc22663818\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 2985f0f6425a413a99c6138dbcc1947a\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 544c4f1baa6d4aa083511f24066dbccf\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: 87cc9f6a0fbf411bb9e5bb0fa77a74d4\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: de5ae2f84adb448181f912b62679b11b\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: a3293a0f57604aeca6b3b23a0cac233d\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 4b3e6a38712b4a5e81e37c328423e0a4\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 7a6a848107f94373bce8f317f8c40d3d\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 6fa95c6c37bb4db580390ea79d17bf8e\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: 1dc95e4b978c4cd1abda09d255c2671d\n",
      "No such comm: e801bb644c9644e9b8421f0ddf3ece22\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: 2ccabfd7ae5c48b8ac441b693cc04a0d\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: a302ad0a7de145b0a1db12de036b1f65\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 2d5cf6472b22415b93056a92bcbb5adf\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9047609fdd924d6db858224e7e5eae0a\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 9a5ddff7f6a94b2781f33ba9e696e3c2\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: 57e9b00500d64d4bbaf1725097a065c4\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: e061bb0f37ac4424a79c0e1c56575d51\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n",
      "No such comm: 1af36c5b2cdf428d98358352287c3c58\n"
     ]
    }
   ],
   "source": [
    " #Compare loss as a function of latent dimensionality\n",
    "\n",
    "latent_dim=n_channels\n",
    "\n",
    "latent_dims = [m[\"latent_dim\"] for m in model_list]\n",
    "nlayers = [m[\"nlayers\"] for m in model_list]\n",
    "val_scores = [m[\"result\"][\"val\"][0][\"test_loss\"] for m in model_list]\n",
    "colors = [m[\"color\"] for m in model_list]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "axes[0].scatter(latent_dims, val_scores, color=colors, marker=\"*\", s=100)\n",
    "axes[0].set_xlabel(\"Latent Dimensionality\")\n",
    "axes[0].set_ylabel(\"Validation Loss\")\n",
    "\n",
    "axes[1].scatter(nlayers, val_scores, color=colors, marker=\"*\", s=100)\n",
    "axes[1].set_xlabel(\"Number of Layers\")\n",
    "axes[1].set_ylabel(\"Validation Loss\")\n",
    "\n",
    "# Scatter plot with latent_dim on x-axis, nlayers on y-axis, and colormap on z-axis (val_scores)\n",
    "scatter = axes[2].scatter(latent_dims, nlayers, c=val_scores, cmap='viridis', marker=\"s\", s=600)\n",
    "axes[2].set_xlabel(\"Latent Dimensionality\")\n",
    "axes[2].set_ylabel(\"Number of Layers\")\n",
    "axes[2].set_title(\"Validation Loss\")\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(scatter, ax=axes[2])\n",
    "cbar.set_label(\"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18310b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define plot functions\n",
    "\n",
    "def plot(inTensor, axes, color, dim, label, linestyle=\"--\", skip=0):\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i >= len(inTensor)+skip:\n",
    "            break\n",
    "        if i < skip:\n",
    "            continue    \n",
    "        ax.plot(inTensor[i-skip][0][dim].numpy(), linestyle, color=color, label=label)\n",
    "        ax.legend()\n",
    "\n",
    "def reconstruct_signals(input_signal, model_l, axes, dim):\n",
    "    # Reconstruct images\n",
    "    model = model_l[\"model\"].eval()\n",
    "    color = model_l[\"color\"]\n",
    "    label = \"ld %s nl %s\" % (model_l[\"latent_dim\"], model_l[\"nlayers\"])\n",
    "    with torch.no_grad():\n",
    "        reconst_imgs = model(input_signal[0].to(model.device), input_signal[1].to(model.device))    \n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "    plot(reconst_imgs, axes, color, dim, label)\n",
    "\n",
    "def generate_signals(input_latents, model_l, axes, dim, skip=0, color=\"b\"):\n",
    "    # Reconstruct images\n",
    "    model = model_l[\"model\"].eval()\n",
    "    label = \"e=%.1f, x=%.1f, y=%.1f\" % (input_latents[1][0][0].numpy(), input_latents[0][0][0].numpy(), input_latents[0][0][1].numpy())\n",
    "    with torch.no_grad():\n",
    "        reconst_imgs = model.decoder(input_latents[0].to(model.device), input_latents[1].to(model.device))    \n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "    plot(reconst_imgs, axes, color, dim, label, skip=skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the reconstructions with different model hyper-parameters\n",
    "ncols = 4\n",
    "nrows = 16\n",
    "dim = 0\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(15, 40))\n",
    "input_imgs = get_train_images(ncols*nrows)\n",
    "#input_imgs = get_validation_images(ncols*nrows)\n",
    "\n",
    "for m in model_list:\n",
    "    reconstruct_signals(input_imgs, m, axes, dim)\n",
    "plot(input_imgs[0], axes, \"black\", dim=dim, label=\"input\", linestyle=\"-\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af705ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the latent space\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import ipywidgets as widgets\n",
    "    \n",
    "# Create the slider\n",
    "ene_slider = widgets.FloatSlider(value=0.5, min=0, max=1, step=0.01, description='Energy:')\n",
    "nch = get_train_images(1)[1].shape[1] - 1\n",
    "ch_dropdown = widgets.Dropdown(\n",
    "    options=[(f'Channel {i}', i) for i in range(-1,nch+1)],\n",
    "    value=0,\n",
    "    description='Channel:',\n",
    ")\n",
    "# Display the slider\n",
    "display(ch_dropdown)\n",
    "display(ene_slider)\n",
    "\n",
    "idx_test = 0\n",
    "\n",
    "def get_histo(idx_ch):\n",
    "    with torch.no_grad():\n",
    "        model_list[idx_test][\"model\"].eval()\n",
    "        dataset = get_train_images(500_000)\n",
    "        # Filter the dataset\n",
    "        if idx_ch >= 0:\n",
    "            dataset = (dataset[0][dataset[1][:, idx_ch+1] == 1], \n",
    "                       dataset[1][dataset[1][:, idx_ch+1] == 1])\n",
    "        avg_id = dataset[1].mean(dim=0)\n",
    "\n",
    "        \n",
    "\n",
    "        histoOut = torch.histogramdd(   model_list[idx_test][\"model\"].forward(dataset[0].to(model_list[idx_test][\"model\"].device)),\n",
    "                                        bins=5_000,\n",
    "                                        range = None,\n",
    "                                        )\n",
    "        histoOut[0].detach().numpy()\n",
    "\n",
    "        return [histoOut, avg_id]\n",
    "\n",
    "\n",
    "#Create the 2 canvases\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "                \n",
    "def on_ch_dropdown_change(change):\n",
    "    value = change['new']\n",
    "    histo, avg_id = get_histo(value)\n",
    "\n",
    "    colors=[\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\", \"orange\", \"purple\", \"brown\", \"pink\", \"olive\", \"cyan\"]\n",
    "\n",
    "    axes[0].imshow( histo[0], \n",
    "                    extent=[histo[1][0][0], \n",
    "                            histo[1][0][-1],\n",
    "                            histo[1][1][0], \n",
    "                            histo[1][1][-1]], \n",
    "                    aspect='auto', \n",
    "                    origin='lower', \n",
    "                    norm=matplotlib.colors.LogNorm())\n",
    "                    \n",
    "    def on_histo_double_click(event):\n",
    "        if event.dblclick:\n",
    "            x = event.xdata\n",
    "            y = event.ydata\n",
    "            if x is not None and y is not None:\n",
    "\n",
    "                #Get coordinates\n",
    "                last_click = [x, y] \n",
    "                print(\"[%.2f, %.2f]\" % (x, y))\n",
    "\n",
    "                color=colors.pop(0)\n",
    "                #Annote in the plot\n",
    "                axes[0].annotate(\"[%.2f, %.2f]\" % (x, y), (x, y), color=color, bbox=dict(facecolor='white', edgecolor='white', alpha=0.5))\n",
    "                axes[0].plot(x, y, 'o', color=color)\n",
    "\n",
    "                #Plot the signal\n",
    "                def on_ene_slider_change(change):\n",
    "                    value = change['new']\n",
    "                    double_click_tensor = torch.FloatTensor([last_click])\n",
    "                    id_tensor = avg_id.unsqueeze(0).repeat(double_click_tensor.size(0), 1)\n",
    "                    id_tensor[:, 0] = value\n",
    "                    generate_signals([double_click_tensor, id_tensor], model_list[idx_test], axes, dim=0, skip=1, color=color)\n",
    "\n",
    "                ene_slider.observe(on_ene_slider_change, names='value')\n",
    "\n",
    "    fig.canvas.mpl_connect('button_press_event', on_histo_double_click)\n",
    "\n",
    "ch_dropdown.observe(on_ch_dropdown_change, names='value')            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding similar signals in the latent space and then checking the signals\n",
    "\n",
    "def embed_imgs(model, data_loader):\n",
    "    # Encode all images in the data_laoder using model, and return both images and encodings\n",
    "    img_list, embed_list = [], []\n",
    "    model.eval()\n",
    "    for imgs, ids in data_loader:\n",
    "        with torch.no_grad():\n",
    "            z = model.encoder(imgs.to(model.device), ids.to(model.device))\n",
    "        img_list.append(imgs)\n",
    "        embed_list.append(z)\n",
    "    return (torch.cat(img_list, dim=0), torch.cat(embed_list, dim=0))\n",
    "\n",
    "\n",
    "train_img_embeds = embed_imgs(model_list[idx_test][\"model\"], train_loader)\n",
    "test_img_embeds = embed_imgs(model_list[idx_test][\"model\"], test_loader)\n",
    "\n",
    "def find_similar_images(query_img, query_z, key_embeds, ax, K=8, dim=0):\n",
    "    # Find closest K images. We use the euclidean distance here but other like cosine distance can also be used.\n",
    "    dist = torch.cdist(query_z[None, :], key_embeds[1], p=2)\n",
    "    dist = dist.squeeze(dim=0)\n",
    "    dist, indices = torch.sort(dist)\n",
    "    # Plot K closest images\n",
    "    imgs_to_display = torch.cat([query_img[None], key_embeds[0][indices[:K]]], dim=0)\n",
    "    #grid = torchvision.utils.make_grid(imgs_to_display, nrow=K + 1, normalize=True, value_range=(-1, 1))\n",
    "    #grid = grid.permute(1, 2, 0)\n",
    "    #plt.figure(figsize=(12, 3))\n",
    "    #plt.imshow(grid)\n",
    "    #plt.axis(\"off\")\n",
    "    #plt.show()\n",
    "    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\", \"orange\", \"purple\", \"brown\", \"pink\"]\n",
    "    ax.plot(query_img[0][dim].numpy(), color=\"k\", label=\"query\")\n",
    "    for i in range(imgs_to_display.size()[0]):\n",
    "        ax.plot(imgs_to_display[i][0][dim].numpy(), \"--\", color=colors.pop(0), label=\"latent_dim %i\" % latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the closest images for the first N test images as example\n",
    "ncols = 6\n",
    "nrows = 6\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    find_similar_images(test_img_embeds[0][i], test_img_embeds[1][i], key_embeds=train_img_embeds, K=6, ax=ax, dim=0)\n",
    "\n",
    "#This does not make sense, i probabily did something wrong"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
