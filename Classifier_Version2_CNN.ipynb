{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e90170",
   "metadata": {},
   "source": [
    "Objetive of the project could be finding a regularisation of the latent space to extract high-level features of the signals obtained from the Sauron Semiconductors placed inside the AGATA.\n",
    "\n",
    "Things to do:\n",
    "-Solve errors of Calibration_modified.py.\n",
    "-Find regularisation strategies from the book ML for Physicist in this unsupervised autoencoder.\n",
    "-Add .root dataset of Daniele Mengoni to the code.\n",
    "-Improve the noise reduction by including other techniques to the dataset (e.g. cross-validation).\n",
    "-Add axis units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f5878a-f63d-4176-95bc-635d4dd1f85d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/luna/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/luna/.cache/torch_extensions/py311_cu118/PIDDataset/build.ninja...\n",
      "Building extension module PIDDataset...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module PIDDataset...\n"
     ]
    }
   ],
   "source": [
    "#Loading the libraries and compiling the c++ module\n",
    "\n",
    "from torch.utils.cpp_extension import load\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "#import seaborn as sn\n",
    "import os\n",
    "import glob\n",
    "import lightning\n",
    "import matplotlib\n",
    "import math\n",
    "import torchmetrics\n",
    "import pytorch_model_summary as pms\n",
    "\n",
    "\n",
    "#from autoencoder import *\n",
    "\n",
    "#Compile the c++ module\n",
    "pid_dataset = load(name=\"PIDDataset\",\n",
    "                   sources=[\"PidDataset.cpp\",\"ReadRawData.cpp\",\"ReadBinaryData.cpp\", \"mwdlib.cpp\"],\n",
    "                   verbose=True,\n",
    "                   extra_cflags=['-O3'],\n",
    "                  )\n",
    "\n",
    "# TO SHOW INTERACTIVE PLOT\n",
    "%matplotlib widget\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dacbaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define NN parameters\n",
    "\n",
    "\n",
    "derivative_order=1\n",
    "normalized=False\n",
    "convolutional=True #I can try to put this to False!!!\n",
    "dropout_p=0.0 #In big NN we can put this parameter to 50% to avoid overfitting, by eliminating neurons. In this case, a smaller NN, it is not that useful.\n",
    "#nLayers_list = [20, 30, 40, 50]\n",
    "nLayers_list = [6,8,10]\n",
    "#act_fn = torch.nn.ReLU\n",
    "kernel_size = 6\n",
    "stride = 2\n",
    "act_fn = torch.nn.GELU #Activation function\n",
    "#pooling_kernel_size = 2\n",
    "\n",
    "#Training parameters\n",
    "batch_size = 300 #1000 was working. \n",
    "learning_rate = 2e-3 #If it's too big, it may go out of the gradient descent.\n",
    "#batch_size = 5000 #this only makes things slow\n",
    "retrain=True #??\n",
    "version_nr = 0\n",
    "EarlyStoppingNr = 10 #15 was working.\n",
    "max_epochs = 100 #before we had 300.\n",
    "exclude_outliers = False\n",
    "\n",
    "\n",
    "\n",
    "#Dataset\n",
    "dataset = \"Fazia\"\n",
    "\n",
    "if dataset == \"Sauron\":\n",
    "    trainDatasetFile = \"./DataFusEvSauron/RU_caendig_i1468_0005_0000.caendat\"\n",
    "    datasetEvents = 3_000_000 #Events=Number of total signals.\n",
    "    samples_number=128\n",
    "    first_sample=0\n",
    "    n_channels=64\n",
    "elif dataset == \"Oscar\":\n",
    "    trainDatasetFile = \"./DataLiFOscar/data_0-7.caendat\"\n",
    "    datasetEvents = 709_755\n",
    "    samples_number=40\n",
    "    first_sample=200\n",
    "    n_channels=16\n",
    "elif dataset == \"Fazia\":\n",
    "    trainDatasetFile = \"./Fazia/Signal_and_IdCal_221.dat\"\n",
    "    datasetEvents = 709_756\n",
    "    samples_number=30\n",
    "    first_sample=14\n",
    "    n_channels=25\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb40f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvNet(lightning.LightningModule):\n",
    "#     def __init__(self,base_channel_size: int, \n",
    "#                  num_classes: int, \n",
    "#                  num_input_channels: int = 1, \n",
    "#                  width: int = 32,\n",
    "#                  height: int = 32,\n",
    "#                  act_fn: object = torch.nn.GELU, \n",
    "#                  dropout_p=0.5,\n",
    "#                  class_weights=None):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "#         if class_weights is not None:\n",
    "#             self.criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "#         else:\n",
    "#             self.criterion = torch.nn.CrossEntropyLoss()\n",
    "#         self.num_classes = num_classes\n",
    "#         c_hid = base_channel_size\n",
    "    \n",
    "#         #self.example_signals = torch.zeros(2, num_input_channels, width, height)\n",
    "#         #self.example_ids = torch.zeros(2, latent_dim + 1)\n",
    "#         #self.example_input_array = (self.example_signals, self.example_ids)\n",
    "#         _padding = [0, 0]\n",
    "#         _stride = [1,stride]\n",
    "#         _kernel_size = [1,kernel_size]\n",
    "\n",
    "        \n",
    "#         self.net1 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(num_input_channels, c_hid, kernel_size=_kernel_size, padding=_padding, stride=_stride, dtype=torch.float32),  # 32x32 => 16x16\n",
    "#             act_fn(),\n",
    "#             torch.nn.Dropout(dropout_p), \n",
    "#             #torch.nn.Conv2d(c_hid, c_hid, kernel_size=_kernel_size, padding=_padding, stride=[1,1], dtype=torch.float32),\n",
    "#             #act_fn(),\n",
    "#             #torch.nn.Dropout(dropout_p), \n",
    "#             torch.nn.Conv2d(c_hid, 2 * c_hid, kernel_size=_kernel_size, padding=_padding, stride=_stride, dtype=torch.float32),  # 16x16 => 8x8\n",
    "#             act_fn(),\n",
    "#             #torch.nn.Dropout(dropout_p), \n",
    "#             #torch.nn.Conv2d(2 * c_hid, 2 * c_hid, kernel_size=_kernel_size, padding=_padding, stride=[1,1], dtype=torch.float32),\n",
    "#             #act_fn(),\n",
    "#             torch.nn.Dropout(dropout_p), \n",
    "#             torch.nn.Conv2d(2 * c_hid, 4 * c_hid, kernel_size=_kernel_size, padding=_padding, stride=_stride, dtype=torch.float32),  # 8x8 => 4x4\n",
    "#             act_fn(),\n",
    "#             torch.nn.Dropout(dropout_p), \n",
    "#             torch.nn.Flatten(),  # Image grid to single feature vector\n",
    "#         )\n",
    "        \n",
    "#         def conv_output_size(h_w, k_size=1, stride=1, pad=0, dilation=1):\n",
    "#             return math.floor(((h_w + (2 * pad) - (dilation * (k_size - 1)) - 1) / stride) + 1)\n",
    "\n",
    "#         height_out = height\n",
    "#         height_out = conv_output_size(height_out, _kernel_size[1], _stride[1], _padding[1])\n",
    "#         #height_out = conv_output_size(height_out, _kernel_size[1], 1, _padding[1])\n",
    "#         height_out = conv_output_size(height_out, _kernel_size[1], _stride[1], _padding[1])\n",
    "#         #height_out = conv_output_size(height_out, _kernel_size[1], 1, _padding[1])\n",
    "#         height_out = conv_output_size(height_out, _kernel_size[1], _stride[1], _padding[1])\n",
    "\n",
    "#         self.net2 = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(4 * c_hid * width * height_out, num_classes, dtype=torch.float32),\n",
    "#             act_fn(),\n",
    "#             #torch.nn.Linear(num_classes, num_classes, dtype=torch.float32),\n",
    "#             #act_fn(),\n",
    "#             torch.nn.Linear(num_classes, num_classes, dtype=torch.float32),\n",
    "#             torch.nn.Softmax(dim=1)\n",
    "#         )\n",
    "\n",
    "# # 1st CHANGES TO NETS: val_acc=0.61\n",
    "# class ConvNet(lightning.LightningModule):\n",
    "#     def __init__(self, base_channel_size: int, \n",
    "#                  num_classes: int, \n",
    "#                  num_input_channels: int = 1, \n",
    "#                  width: int = 32,\n",
    "#                  height: int = 32,\n",
    "#                  act_fn: object = torch.nn.GELU, \n",
    "#                  dropout_p=0.5,\n",
    "#                  class_weights=None):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "#         if class_weights is not None:\n",
    "#             self.criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "#         else:\n",
    "#             self.criterion = torch.nn.CrossEntropyLoss()\n",
    "#         self.num_classes = num_classes\n",
    "#         c_hid = base_channel_size\n",
    "    \n",
    "#         _kernel_size = [1, 3]  # Kernel size 3 for convolutions\n",
    "#         _padding = [0, 1]      # Padding of 1 to keep dimensions similar after convolution\n",
    "#         _stride = [1, 2]       # Stride of 2 to reduce dimensions\n",
    "        \n",
    "#         # Red convolucional\n",
    "#         self.net1 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(num_input_channels, c_hid, kernel_size=_kernel_size[1], padding=_padding[1], stride=_stride[1]),  # 32x32 => 16x16\n",
    "#             act_fn(),\n",
    "#             torch.nn.Dropout(dropout_p), \n",
    "#             torch.nn.Conv2d(c_hid, 2 * c_hid, kernel_size=_kernel_size[1], padding=_padding[1], stride=_stride[1]),  # 16x16 => 8x8\n",
    "#             act_fn(),\n",
    "#             torch.nn.Dropout(dropout_p), \n",
    "#             torch.nn.Conv2d(2 * c_hid, 4 * c_hid, kernel_size=_kernel_size[1], padding=_padding[1], stride=_stride[1]),  # 8x8 => 4x4\n",
    "#             act_fn(),\n",
    "#             torch.nn.Dropout(dropout_p), \n",
    "#             torch.nn.Flatten(),  # Imagen a vector de características\n",
    "#         )\n",
    "\n",
    "#         # Función para calcular la salida de las convoluciones\n",
    "#         def conv_output_size(h_w, k_size=1, stride=1, pad=0, dilation=1):\n",
    "#             return math.floor(((h_w + (2 * pad) - (dilation * (k_size - 1)) - 1) / stride) + 1)\n",
    "\n",
    "#         # Cálculo de la altura después de cada operación convolucional\n",
    "#         height_out = height\n",
    "#         height_out = conv_output_size(height_out, _kernel_size[1], _stride[1], _padding[1])  # 32x32 => 16x16\n",
    "#         height_out = conv_output_size(height_out, _kernel_size[1], _stride[1], _padding[1])  # 16x16 => 8x8\n",
    "#         height_out = conv_output_size(height_out, _kernel_size[1], _stride[1], _padding[1])  # 8x8 => 4x4\n",
    "\n",
    "#         # Red fully-connected (clasificación)\n",
    "#         self.net2 = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(4 * c_hid * height_out * width, num_classes),\n",
    "#             act_fn(),\n",
    "#             torch.nn.Linear(num_classes, num_classes),\n",
    "#             torch.nn.Softmax(dim=1)\n",
    "#         )\n",
    "        \n",
    "\n",
    "\n",
    "#2nd changes to net : val_acc=0.68\n",
    "class ConvNet(lightning.LightningModule):\n",
    "    def __init__(self, base_channel_size: int, \n",
    "                 num_classes: int, \n",
    "                 num_input_channels: int = 1, \n",
    "                 width: int = 50,  # Basado en el input de tu error\n",
    "                 height: int = 50,  # Basado en el input de tu error\n",
    "                 act_fn: object = torch.nn.GELU, \n",
    "                 dropout_p=0.5,\n",
    "                 class_weights=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        if class_weights is not None:\n",
    "            self.criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        else:\n",
    "            self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.num_classes = num_classes\n",
    "        c_hid = base_channel_size\n",
    "\n",
    "        _kernel_size = [1, 3]  # Usamos kernel de 3x3\n",
    "        _padding = [0, 1]      # Padding de 1 para preservar las dimensiones\n",
    "        _stride = [1, 2]       # Stride de 2 para reducir las dimensiones gradualmente\n",
    "\n",
    "        # Red convolucional\n",
    "        self.net1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(num_input_channels, c_hid, kernel_size=_kernel_size[1], padding=_padding[1], stride=_stride[1]),  # Primera convolución\n",
    "            act_fn(),\n",
    "            torch.nn.Dropout(dropout_p), \n",
    "            torch.nn.Conv2d(c_hid, 2 * c_hid, kernel_size=_kernel_size[1], padding=_padding[1], stride=_stride[1]),  # Segunda convolución\n",
    "            act_fn(),\n",
    "            torch.nn.Dropout(dropout_p), \n",
    "            torch.nn.Conv2d(2 * c_hid, 4 * c_hid, kernel_size=_kernel_size[1], padding=_padding[1], stride=_stride[1]),  # Tercera convolución\n",
    "            act_fn(),\n",
    "            torch.nn.Dropout(dropout_p), \n",
    "            torch.nn.Flatten(),  # Aplanamos para la capa fully connected\n",
    "        )\n",
    "\n",
    "        # Función para calcular la salida de las convoluciones\n",
    "        def conv_output_size(h_w, k_size=1, stride=1, pad=0, dilation=1):\n",
    "            return math.floor(((h_w + (2 * pad) - (dilation * (k_size - 1)) - 1) / stride) + 1)\n",
    "\n",
    "        # Cálculo de la altura después de cada operación convolucional\n",
    "        height_out = height\n",
    "        width_out = width\n",
    "\n",
    "        # Primera convolución\n",
    "        height_out = conv_output_size(height_out, _kernel_size[1], _stride[1], _padding[1])  # 50x50 => 25x25\n",
    "        width_out = conv_output_size(width_out, _kernel_size[1], _stride[1], _padding[1])    # 50x50 => 25x25\n",
    "        \n",
    "        # Segunda convolución\n",
    "        height_out = conv_output_size(height_out, _kernel_size[1], _stride[1], _padding[1])  # 25x25 => 12x12\n",
    "        width_out = conv_output_size(width_out, _kernel_size[1], _stride[1], _padding[1])    # 25x25 => 12x12\n",
    "\n",
    "        # Tercera convolución\n",
    "        height_out = conv_output_size(height_out, _kernel_size[1], _stride[1], _padding[1])  # 12x12 => 6x6\n",
    "        width_out = conv_output_size(width_out, _kernel_size[1], _stride[1], _padding[1])    # 12x12 => 6x6\n",
    "\n",
    "        # Red fully-connected (clasificación)\n",
    "        self.net2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4 * c_hid * height_out * width_out, 512),  # Ajustamos a la salida calculada\n",
    "            act_fn(),\n",
    "            torch.nn.Dropout(dropout_p),\n",
    "            torch.nn.Linear(512, num_classes),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.net2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "    def _get_reconstruction_loss(self, batch):\n",
    "        \"\"\"Given a batch of images, this function returns the reconstruction loss (MSE in our case).\"\"\"\n",
    "        x, y = batch  # Y contains channels and energy\n",
    "        x_hat = self.forward(x)\n",
    "        #loss = torch.nn.functional.mse_loss(x_hat, y, reduction=\"mean\")\n",
    "        #y = torch.argmax(y, dim=1)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        #optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        #optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        # Using a scheduler is optional but can be helpful.\n",
    "        # The scheduler reduces the LR if the validation performance hasn't improved for the last N epochs\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.2, patience=3, min_lr=5e-7)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "\n",
    "    #En x_hat necesito hacer un self.forward(x)??? Y antes el numero de clases es el base_channel_size o 25, que sería el número de labels???\n",
    "    #Y los nLayers en bucle como comparo la ccuracy para ver cual es mejor?\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        acc = self.accuracy(x_hat, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        acc = self.accuracy(x_hat, y)\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        ##Save the confusion matrix\n",
    "        #self.cm = np.zeros((self.num_classes, self.num_classes), dtype=int)\n",
    "        #y_true = torch.argmax(y, dim=1)\n",
    "        #y_pred = torch.argmax(x_hat, dim=1)\n",
    "        #for true, pred in zip(y_true, y_pred):\n",
    "        #    self.cm[true, pred] += 1\n",
    "        #    \n",
    "        #fig, ax = plt.subplots()\n",
    "        #ax.imshow(self.cm, cmap='hot', interpolation='nearest')\n",
    "        #ax.set_title('Confusion matrix')\n",
    "        #ax.set_xlabel('Predicted')\n",
    "        #ax.set_ylabel('True')\n",
    "        ##self.log.experiment.add_figure(\"Confusion matrix\", fig)\n",
    "        #self.log('Confusion matrix', fig)\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc': acc, 'preds': x_hat, 'targets': y}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        acc = self.accuracy(x_hat, y)\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('test_acc', acc, on_step=False, on_epoch=True)\n",
    "        return {'test_loss': loss, 'test_acc': acc, 'preds': x_hat, 'targets': y}\n",
    "    \n",
    "    #def validation_epoch_end(self, outputs):\n",
    "    #    preds = torch.cat([x['preds'] for x in outputs])\n",
    "    #    targets = torch.cat([x['targets'] for x in outputs])\n",
    "    #    self.log_confusion_matrix(preds, targets)\n",
    "\n",
    "    #def log_confusion_matrix(self, preds, targets):\n",
    "    #    preds = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "    #    targets = targets.cpu().numpy()\n",
    "    #    cf_matrix = confusion_matrix(targets, preds)\n",
    "    #    df_cm = pd.DataFrame(cf_matrix, index=[i for i in range(cf_matrix.shape[0])],\n",
    "    #                         columns=[i for i in range(cf_matrix.shape[1])])\n",
    "    #    plt.figure(figsize=(12, 7))\n",
    "    #    sn.heatmap(df_cm, annot=True, fmt='d')\n",
    "    #    plt.xlabel('Predicted')\n",
    "    #    plt.ylabel('True')\n",
    "    #    plt.title('Confusion Matrix')\n",
    "    #    self.logger.experiment.add_figure(\"Confusion matrix\", plt.gcf(), self.current_epoch)\n",
    "    #    plt.close()\n",
    "\n",
    "    #def test_step(self, batch, batch_idx):\n",
    "    #    x, y = batch\n",
    "    #    x_hat = self(x)\n",
    "    #    loss = self.criterion(x_hat, y)\n",
    "    #    acc = self.accuracy(x_hat, y)\n",
    "    #    self.log('test_loss', loss)\n",
    "    #    self.log('test_acc', acc)\n",
    "    #    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f005f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "\n",
    "\n",
    "split_percent = [0.8, 0.1, 0.1] #90% for training, 5% for testing and 5% for validating.\n",
    "\n",
    "[train_dataset, val_dataset, test_dataset] = torch.utils.data.random_split(\n",
    "                pid_dataset.PIDDataset(root=trainDatasetFile, \n",
    "                                       mode=pid_dataset.kTrain, \n",
    "                                       count=datasetEvents, \n",
    "                                       nder=derivative_order, \n",
    "                                       nsamples=samples_number, \n",
    "                                       firstsample=first_sample,\n",
    "                                       nchannels=n_channels,\n",
    "                                       normalized=normalized,\n",
    "                                       discardenergies=False,\n",
    "                                       minenergy=0.55,\n",
    "                                       maxenergy=100,),\n",
    "                                       split_percent)\n",
    "\n",
    "#Sampler to normalize the amount of types of each class\n",
    "weights = torch.zeros(len(train_dataset))\n",
    "class_counts = torch.zeros(n_channels)\n",
    "\n",
    "#cont the occurrence of each class in the dataset\n",
    "for i in range(len(train_dataset)):\n",
    "    class_counts[train_dataset[i][1]] += 1\n",
    "\n",
    "#calculate the weights\n",
    "for i in range(len(train_dataset)):\n",
    "    weights[i] = class_counts[train_dataset[i][1]]\n",
    "    \n",
    "weights = 1.0 / weights\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "sampler = torch.utils.data.WeightedRandomSampler(weights=weights, num_samples=len(train_dataset), replacement=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           #shuffle=True, \n",
    "                                           drop_last=True, \n",
    "                                           pin_memory=True, \n",
    "                                           num_workers=4,\n",
    "                                           sampler=sampler)\n",
    "#Batch size: number of signals per batch.\n",
    "#Shuffle: shuffle data at every epoch.\n",
    "#Epoch: During an epoch, the model processes each training example once, \n",
    "#and the learning process updates the model's parameters based on the loss calculated from the training examples.\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                         batch_size=2_000, \n",
    "                                         shuffle=False, \n",
    "                                         drop_last=False, \n",
    "                                         num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=2_000, \n",
    "                                          shuffle=False, \n",
    "                                          drop_last=False, \n",
    "                                          num_workers=4)\n",
    "\n",
    "def get_train_images(num):\n",
    "    #return [torch.stack([train_dataset[i][0] for i in range(num)], dim=0), torch.stack([train_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([train_dataset[i][0] for i in range(num)], dim=0)\n",
    "    #Here i is the batch and what is 0? dim=0 is the dimension of the output tensor.\n",
    "    #What are IDs???\n",
    "\n",
    "def get_train_labels(num):\n",
    "    #return [torch.stack([train_dataset[i][0] for i in range(num)], dim=0), torch.stack([train_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([train_dataset[i][1] for i in range(num)], dim=0)\n",
    "    #Here i is the batch and what is 0? dim=0 is the dimension of the output tensor.\n",
    "    #What are IDs???\n",
    "\n",
    "def get_validation_images(num):\n",
    "    #return [torch.stack([val_dataset[i][0] for i in range(num)], dim=0), torch.stack([val_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([val_dataset[i][0] for i in range(num)], dim=0)\n",
    "\n",
    "def get_validation_labels(num):\n",
    "    #return [torch.stack([val_dataset[i][0] for i in range(num)], dim=0), torch.stack([val_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([val_dataset[i][1] for i in range(num)], dim=0)\n",
    "    \n",
    "def get_test_images(num):\n",
    "    #return [torch.stack([test_dataset[i][0] for i in range(num)], dim=0), torch.stack([test_dataset[i][1] for i in range(num)], dim=0)]\n",
    "    return torch.stack([test_dataset[i][0] for i in range(num)], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dffd3aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1       [4, 6, 1, 16]              60              60\n",
      "            GELU-2       [4, 6, 1, 16]               0               0\n",
      "         Dropout-3       [4, 6, 1, 16]               0               0\n",
      "          Conv2d-4       [4, 12, 1, 8]             660             660\n",
      "            GELU-5       [4, 12, 1, 8]               0               0\n",
      "         Dropout-6       [4, 12, 1, 8]               0               0\n",
      "          Conv2d-7       [4, 24, 1, 4]           2,616           2,616\n",
      "            GELU-8       [4, 24, 1, 4]               0               0\n",
      "         Dropout-9       [4, 24, 1, 4]               0               0\n",
      "        Flatten-10             [4, 96]               0               0\n",
      "         Linear-11            [4, 512]          49,664          49,664\n",
      "           GELU-12            [4, 512]               0               0\n",
      "        Dropout-13            [4, 512]               0               0\n",
      "         Linear-14             [4, 25]          12,825          12,825\n",
      "        Softmax-15             [4, 25]               0               0\n",
      "=======================================================================\n",
      "Total params: 65,825\n",
      "Trainable params: 65,825\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1       [4, 8, 1, 16]              80              80\n",
      "            GELU-2       [4, 8, 1, 16]               0               0\n",
      "         Dropout-3       [4, 8, 1, 16]               0               0\n",
      "          Conv2d-4       [4, 16, 1, 8]           1,168           1,168\n",
      "            GELU-5       [4, 16, 1, 8]               0               0\n",
      "         Dropout-6       [4, 16, 1, 8]               0               0\n",
      "          Conv2d-7       [4, 32, 1, 4]           4,640           4,640\n",
      "            GELU-8       [4, 32, 1, 4]               0               0\n",
      "         Dropout-9       [4, 32, 1, 4]               0               0\n",
      "        Flatten-10            [4, 128]               0               0\n",
      "         Linear-11            [4, 512]          66,048          66,048\n",
      "           GELU-12            [4, 512]               0               0\n",
      "        Dropout-13            [4, 512]               0               0\n",
      "         Linear-14             [4, 25]          12,825          12,825\n",
      "        Softmax-15             [4, 25]               0               0\n",
      "=======================================================================\n",
      "Total params: 84,761\n",
      "Trainable params: 84,761\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1      [4, 10, 1, 16]             100             100\n",
      "            GELU-2      [4, 10, 1, 16]               0               0\n",
      "         Dropout-3      [4, 10, 1, 16]               0               0\n",
      "          Conv2d-4       [4, 20, 1, 8]           1,820           1,820\n",
      "            GELU-5       [4, 20, 1, 8]               0               0\n",
      "         Dropout-6       [4, 20, 1, 8]               0               0\n",
      "          Conv2d-7       [4, 40, 1, 4]           7,240           7,240\n",
      "            GELU-8       [4, 40, 1, 4]               0               0\n",
      "         Dropout-9       [4, 40, 1, 4]               0               0\n",
      "        Flatten-10            [4, 160]               0               0\n",
      "         Linear-11            [4, 512]          82,432          82,432\n",
      "           GELU-12            [4, 512]               0               0\n",
      "        Dropout-13            [4, 512]               0               0\n",
      "         Linear-14             [4, 25]          12,825          12,825\n",
      "        Softmax-15             [4, 25]               0               0\n",
      "=======================================================================\n",
      "Total params: 104,417\n",
      "Trainable params: 104,417\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Debug cell???\n",
    "\n",
    "for nLayers in nLayers_list:\n",
    "    \n",
    "    test = ConvNet(base_channel_size=nLayers, \n",
    "                                num_classes=n_channels,\n",
    "                                width=derivative_order, \n",
    "                                height=samples_number, \n",
    "                                act_fn=act_fn, \n",
    "                                dropout_p=dropout_p,\n",
    "                                class_weights=None)\n",
    "    \n",
    "    \n",
    "    x = test(get_train_images(4))\n",
    "    #print(autoenctest._get_reconstruction_loss((x,y)))\n",
    "    print(pms.summary(test, get_train_images(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "966c82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback functions\n",
    "\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/classifier\")\n",
    "\n",
    "class ConfusionMatrixCallback(lightning.pytorch.callbacks.Callback):\n",
    "    def __init__(self, input, labels, every_n_epochs=1, data_type=\"train\"):\n",
    "        super().__init__()# It's often used to call the parent class's __init__ method to ensure that the parent class is properly initialized when creating an instance of the derived class.\n",
    "        # Only save uthose images every N epochs (otherwise tensorboard gets quite large)\n",
    "        self.every_n_epochs = every_n_epochs\n",
    "        self.input = input\n",
    "        self.labels = labels\n",
    "        self.data_type = data_type\n",
    "\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        signals = self.input.to(pl_module.device)\n",
    "        with torch.no_grad():\n",
    "            pl_module.eval()\n",
    "            print(signals.shape)\n",
    "            output = pl_module(signals)\n",
    "            pl_module.train()\n",
    "\n",
    "        #calculate te confusion matrix\n",
    "        cm = torchmetrics.ConfusionMatrix(num_classes=pl_module.num_classes, task='multiclass')\n",
    "        cm.update(output, self.labels)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "        cm = cm.compute().numpy()\n",
    "        cax = ax.matshow(cm, cmap='Blues')\n",
    "        plt.colorbar(cax)\n",
    "        for (i, j), val in np.ndenumerate(cm):\n",
    "            ax.text(j, i, f'{val}', ha='center', va='center', color='black')\n",
    "\n",
    "        #ax.imshow(cm.compute().numpy(), cmap='hot', interpolation='nearest')\n",
    "        ax.set_title('Confusion matrix')\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('True')\n",
    "        if self.data_type == \"train\":\n",
    "            trainer.logger.experiment.add_figure(\"Confusion Matrix Train\", fig, global_step=trainer.global_step)\n",
    "        elif self.data_type == \"validation\":\n",
    "            trainer.logger.experiment.add_figure(\"Confusion Matrix Validation\", fig, global_step=trainer.global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63f90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training function definition\n",
    "\n",
    "def train(base_channel_size, retrain=False):\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "\n",
    "    netName = \"model_bc%i_do%i\" % (base_channel_size, derivative_order)\n",
    "    \n",
    "    callbacks=[\n",
    "        #lightning.pytorch.callbacks.ModelCheckpoint(save_weights_only=True),\n",
    "        #ImageCallback(every_n_epochs=1),\n",
    "        ConfusionMatrixCallback(input=get_train_images(40_000), labels=get_train_labels(40_000), every_n_epochs=1, data_type=\"train\"),\n",
    "        ConfusionMatrixCallback(input=get_validation_images(10_000), labels=get_validation_labels(10_000), every_n_epochs=1, data_type=\"validation\"),\n",
    "        lightning.pytorch.callbacks.LearningRateMonitor(\"epoch\"),\n",
    "        lightning.pytorch.callbacks.ModelCheckpoint(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_top_k=1,  # Save only the best checkpoint based on validation loss\n",
    "            save_last=True,  # Save the latest checkpoint\n",
    "            filename='{epoch}-{val_loss:.2f}',  # Customize the filename with epoch and validation loss\n",
    "            verbose=True,\n",
    "        ),\n",
    "        lightning.pytorch.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=EarlyStoppingNr,\n",
    "            verbose=False,\n",
    "            min_delta=0.00,\n",
    "        ),\n",
    "        # Other callbacks...\n",
    "    ]\n",
    "\n",
    "    trainer = lightning.Trainer(\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, netName),\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        callbacks=callbacks,\n",
    "        max_epochs=max_epochs,\n",
    "        logger=lightning.pytorch.loggers.tensorboard.TensorBoardLogger(\"saved_models/classifier\", \n",
    "                                                                       name=netName),\n",
    "    )\n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    #ckpt_files = glob.glob('saved_models/autoencoder/%s/version_0/checkpoints/epoch*.ckpt' % (netName))\n",
    "    ckpt_files = glob.glob('saved_models/classifier/%s/version_%i/checkpoints/epoch*.ckpt' % (netName, version_nr))\n",
    "\n",
    "    if ckpt_files and not retrain:\n",
    "        print(\"Found pretrained model, called %s\" % ckpt_files[0])\n",
    "        model = ConvNet.load_from_checkpoint(ckpt_files[0])\n",
    "        #model.to(\"cuda\")\n",
    "        model.to(\"cpu\")\n",
    "    else:   \n",
    "        #ids_nr = get_test_images(1)[1].shape[1] - 1 \n",
    "        model = ConvNet(base_channel_size=base_channel_size, \n",
    "                                    num_classes=n_channels,\n",
    "                                    width=derivative_order, \n",
    "                                    height=samples_number, \n",
    "                                    act_fn=act_fn, \n",
    "                                    dropout_p=dropout_p,\n",
    "                                    class_weights=None)\n",
    "                        \n",
    "        print(\"testing on a single batch...\")\n",
    "        print(\"inished testing on a single batch...\")\n",
    "\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "        print(\"Finished training, saving model...\")\n",
    "\n",
    "        # Test best model on validation and test set\n",
    "        val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n",
    "        test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "        result = {\"test\": test_result, \"val\": val_result}\n",
    "        return model, result\n",
    "        print(\"Finished training, saving model...\")\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "    result = {\"test\": test_result, \"val\": val_result}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b155217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luna/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | accuracy  | MulticlassAccuracy | 0     \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | net1      | Sequential         | 3.3 K \n",
      "3 | net2      | Sequential         | 62.5 K\n",
      "-------------------------------------------------\n",
      "65.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "65.8 K    Total params\n",
      "0.263     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on a single batch...\n",
      "inished testing on a single batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luna/miniconda3/envs/pytorch/lib/python3.11/site-packages/lightning/pytorch/loggers/tensorboard.py:187: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9840aedcd9b4c4bb885eaaf58bacff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65323d7200c47f990275ea1b167a1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f06cae67b145a2b3e40dd7ec5ea55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 964: 'val_loss' reached 3.02752 (best 3.02752), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=0-val_loss=3.03.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c206b38c8684cc6b7bbcfae5998819b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1928: 'val_loss' reached 2.91381 (best 2.91381), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=1-val_loss=2.91.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eeb015968da4fdfb988581c1f214895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2892: 'val_loss' reached 2.72432 (best 2.72432), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=2-val_loss=2.72.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320fcf33a4684b21a6d9df9f64a92dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 3856: 'val_loss' reached 2.68777 (best 2.68777), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=3-val_loss=2.69.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14958753e73048d9a60b250f33ea48fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 4820: 'val_loss' reached 2.67635 (best 2.67635), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=4-val_loss=2.68.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37be3836b5684b199020d1c6d8774df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 5784: 'val_loss' reached 2.65831 (best 2.65831), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=5-val_loss=2.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c24fbfe01f49339a27366783f40a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 6748: 'val_loss' reached 2.65565 (best 2.65565), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=6-val_loss=2.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd8a4a58a5b4de1a4e2719cf4205947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 7712: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b837e61b25428b8b72e45891ff7dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 8676: 'val_loss' reached 2.65542 (best 2.65542), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=8-val_loss=2.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942867dd402c40ec84f9ac97e861a93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 9640: 'val_loss' reached 2.65107 (best 2.65107), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=9-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f449465660347568c808f9eb24d199e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 10604: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca19ba2b27e4f139c69f459b9a5b513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 11568: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbeaa3b3b1b4468b6a3a7fcb602a066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 12532: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987abf8c0da9413cb139bd64fe45ac39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 13496: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552c49347551478698aebf0220333297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 14460: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622f317a13b0401ea8dd2d1621f91304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 15424: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10baca32c50441887675b614d6e4c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 16388: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65874397a2414d59b759ee3e2b6067f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 17352: 'val_loss' reached 2.64707 (best 2.64707), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=17-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a7c2581e2c4d7e9e60778ef6eeaca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 18316: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7842bef0cd40f0a85d2c66f0486f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 19280: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78774538cd184e928627a5525695b0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 20244: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5ac13ad12048169e5b224015cdb9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 21208: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f279e88e2684fdab341d0f13b3a5c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 22172: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a92e94fdb424b81a9e064fdf441345c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 23136: 'val_loss' reached 2.64703 (best 2.64703), saving model to 'saved_models/classifier/model_bc6_do1/version_3/checkpoints/epoch=23-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad47cd4d823043ea94621cfbb5d6e106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 24100: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee27b255e034193a2a6c88e451362dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 25064: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cece17b8d468411ca41e3b0a46d71ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 26028: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba30da9eae994dee8a14c3c8cbe3af97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 26992: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbaa38b2fc07400892ba33bccf586a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 27956: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4481744b46dd4081b7e18077c4395b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 28920: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff7a520cb554e4ea54484ebe9c9df0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 29884: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799b3168c89b4f81b495ebb525b25979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 30848: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117a5923e9254bf5ab6da62052fa6b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 31812: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1c7c5a22fb4939b8bd6e602c99bb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 32776: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training, saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb92d57e3bf74013bd682e8132f60a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0c3b64d8544bb7871d2f578c884e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | accuracy  | MulticlassAccuracy | 0     \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | net1      | Sequential         | 5.9 K \n",
      "3 | net2      | Sequential         | 78.9 K\n",
      "-------------------------------------------------\n",
      "84.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "84.8 K    Total params\n",
      "0.339     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on a single batch...\n",
      "inished testing on a single batch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce007e832e44a98a38402eb9f92ea8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e686446382c149aaaffe0a200e029166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64938e1015ba46baa3f7a35336f66aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 964: 'val_loss' reached 3.00202 (best 3.00202), saving model to 'saved_models/classifier/model_bc8_do1/version_1/checkpoints/epoch=0-val_loss=3.00.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a850aecf0054b47a0e73b797ff9cfda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1928: 'val_loss' reached 2.76688 (best 2.76688), saving model to 'saved_models/classifier/model_bc8_do1/version_1/checkpoints/epoch=1-val_loss=2.77.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758a5952fe4b41e7a36d6ac2484751fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2892: 'val_loss' reached 2.76060 (best 2.76060), saving model to 'saved_models/classifier/model_bc8_do1/version_1/checkpoints/epoch=2-val_loss=2.76.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f43665c5f394c6086cb850110bc970b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 3856: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b8bc1ed3564ff89e4fc241d635a164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 4820: 'val_loss' reached 2.76054 (best 2.76054), saving model to 'saved_models/classifier/model_bc8_do1/version_1/checkpoints/epoch=4-val_loss=2.76.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e6e0402b3e4700ac701c6b0b75a4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 5784: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0172d1ea614c73b8ef7ab47d172363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 6748: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97947202701432987d47bb71fdf27b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 7712: 'val_loss' reached 2.75586 (best 2.75586), saving model to 'saved_models/classifier/model_bc8_do1/version_1/checkpoints/epoch=7-val_loss=2.76.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ad3371a0ef427bbb2fbd92842e86e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 8676: 'val_loss' reached 2.75581 (best 2.75581), saving model to 'saved_models/classifier/model_bc8_do1/version_1/checkpoints/epoch=8-val_loss=2.76.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6c0d43702f457a9a907f2ce5d52b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 9640: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6e6a57e19e4681aefa1c4a7d2489a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 10604: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df0026179af4a8f8710e1445c107da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 11568: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40994ed195d4bcbb035331cb65b5381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 12532: 'val_loss' reached 2.75547 (best 2.75547), saving model to 'saved_models/classifier/model_bc8_do1/version_1/checkpoints/epoch=12-val_loss=2.76.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd42a3b105e4f929e5e23915974c6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 13496: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634dc642a8fe4c93be84f6fc31d064d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 14460: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6d655f63584e8cb77e4cf57ef64eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 15424: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44d319e6c3d49f09e7cb32c7256dc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 16388: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e23cdfada5a49549ad9fd1fd8a9ec6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 17352: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcedf78273e4cfabafc498cedd997ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 18316: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00930884688549bea19ca268f83ebb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 19280: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a870c46cb44b49cb97fca513f4aeded9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 20244: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40c83f6f95749eda3746e1d879248fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 21208: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd20e961f9004d1e94c8b915694d5a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 22172: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training, saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106a6edb0af649439d2bfde7062b66dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423478cb78ec480fa84f3f1db858a7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: saved_models/classifier/model_bc10_do1\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | accuracy  | MulticlassAccuracy | 0     \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | net1      | Sequential         | 9.2 K \n",
      "3 | net2      | Sequential         | 95.3 K\n",
      "-------------------------------------------------\n",
      "104 K     Trainable params\n",
      "0         Non-trainable params\n",
      "104 K     Total params\n",
      "0.418     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on a single batch...\n",
      "inished testing on a single batch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c375620848c47c8b2af6438fd3631a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d2cec050c643aab9f6afee1e942ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3386da32a3749dfa5bc411b5ec1f9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 964: 'val_loss' reached 3.07025 (best 3.07025), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=0-val_loss=3.07.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949cb40257d94ad38cb593bb25095bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1928: 'val_loss' reached 3.03495 (best 3.03495), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=1-val_loss=3.03.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390b775c0488431093c4e6e22770d5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2892: 'val_loss' reached 2.71708 (best 2.71708), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=2-val_loss=2.72.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8741137538b743099ce93e14186cddd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 3856: 'val_loss' reached 2.68531 (best 2.68531), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=3-val_loss=2.69.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1ef0f3c4984f188f7243a091c28433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 4820: 'val_loss' reached 2.67595 (best 2.67595), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=4-val_loss=2.68.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f49ddec2b2b45c497fda8146cb6102d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 5784: 'val_loss' reached 2.67351 (best 2.67351), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=5-val_loss=2.67.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afe958ace4e4326bad1e36a981bef7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 6748: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c95a0958a140e7a3a03aa0ae18d068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 7712: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682b2ea16cc54d69a08fa78df92fbe8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 8676: 'val_loss' reached 2.66380 (best 2.66380), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=8-val_loss=2.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8359728e0049f2845b92d2a0174160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 9640: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b391513bb9394113a8a1f221218afba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 10604: 'val_loss' reached 2.66048 (best 2.66048), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=10-val_loss=2.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b41dde7b22c414c96d10eebd7160d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 11568: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721f6e787d9741a3969a7fd1ee65f55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 12532: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76722101751c439481b68062e91f11d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 13496: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4960b798ab94b55a9d894fd7809bc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 14460: 'val_loss' reached 2.65783 (best 2.65783), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=14-val_loss=2.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a895e4b4d58c4510a4db1e896c470022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 15424: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1c8b78e1ac453880b57f92eefaeb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 16388: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0d8f313c7140409e58021656cfb246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 17352: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f796781075a448b5a996a91779290134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 18316: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cf1ee4789a4cdd85bad682bf88f12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 19280: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c195999b5c40caa915a32684dbdecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 20244: 'val_loss' reached 2.65705 (best 2.65705), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=20-val_loss=2.66.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659115681be241b190b7aeefe6d7dc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 21208: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2628a010e2cd4b9c9fb68d948fda4dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 22172: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9a2bda7f4f4359b28ca9b6446f4477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 23136: 'val_loss' reached 2.65445 (best 2.65445), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=23-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c447520bb1444db13a4326f5f8f2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 24100: 'val_loss' reached 2.65434 (best 2.65434), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=24-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9a13fc3c5243a6a3e8e6f7df7150dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 25064: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cef281054d646979d835c00601e1315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 26028: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd58f6e33654922b2833e25b6e77006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 26992: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27e114ce49b4634ab771d7a393698c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 27956: 'val_loss' reached 2.65349 (best 2.65349), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=28-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa8a8efbbf14b8f91621ae29836a4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 28920: 'val_loss' reached 2.65305 (best 2.65305), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=29-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac321f68b6b4328945eb09dabec658d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 29884: 'val_loss' reached 2.65304 (best 2.65304), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=30-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734cf876824d449485aa98160ccd4685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 30848: 'val_loss' reached 2.65277 (best 2.65277), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=31-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4405b0dc9da4500bb40e60603eb6bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 31812: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec6018afc5b466e9ce87179b377d559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 32776: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4d6be7b4fe4bfb8aef6f3eb79fde24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 33740: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5615faac66f4473b9725dfbcd5d4e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, global step 34704: 'val_loss' reached 2.65267 (best 2.65267), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=35-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6954d8302641efa484d0fb6c79bd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, global step 35668: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe71d4d759fb442e94c39e9684382f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 36632: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe7d6bfad4142898582ca7550bb0c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, global step 37596: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b166bdae714753b6b7f66a3af06c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 38560: 'val_loss' reached 2.65235 (best 2.65235), saving model to 'saved_models/classifier/model_bc10_do1/version_0/checkpoints/epoch=39-val_loss=2.65.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5f56fec7a6459ab12696411fdc662f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 39524: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eddf8cc3ece45e095bccfeae601c462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, global step 40488: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883c421129f6416299b69e922253ad57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 41452: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2113ae3dbb347d9be034d97e7baaf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 42416: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bab28c7cb974a1fb505acd5901c6265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, global step 43380: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17be11f0e76f46d9a93fc3155c17c3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, global step 44344: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e766a7cbcec404996aefe44292eafff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46, global step 45308: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2696812d044677beda2c8e1f4ffe55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, global step 46272: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5dbf48adc84ca188fbcd4ff994fd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, global step 47236: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a0f8157b484cae8d44a5c9ea3afbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 1, 1, 31])\n",
      "torch.Size([10000, 1, 1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 48200: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training, saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f6cd892b7c4b2488a93a6f604410e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedcd11e32004379b51c090b49d56c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: 2772845460254a91be602c57aa97cf2e\n",
      "No such comm: fbd1f4f2a4ba4c7685349b3174076506\n",
      "No such comm: fbd1f4f2a4ba4c7685349b3174076506\n",
      "No such comm: fbd1f4f2a4ba4c7685349b3174076506\n",
      "No such comm: fbd1f4f2a4ba4c7685349b3174076506\n",
      "No such comm: fbd1f4f2a4ba4c7685349b3174076506\n",
      "No such comm: fbd1f4f2a4ba4c7685349b3174076506\n",
      "No such comm: bf5815d81e3743c1ba2d5a2a1376e3f6\n",
      "No such comm: bf5815d81e3743c1ba2d5a2a1376e3f6\n",
      "No such comm: bf5815d81e3743c1ba2d5a2a1376e3f6\n",
      "No such comm: bf5815d81e3743c1ba2d5a2a1376e3f6\n",
      "No such comm: bf5815d81e3743c1ba2d5a2a1376e3f6\n",
      "No such comm: bf5815d81e3743c1ba2d5a2a1376e3f6\n",
      "No such comm: 88c759405ec541a0ac15e4771e92826b\n",
      "No such comm: 88c759405ec541a0ac15e4771e92826b\n",
      "No such comm: 88c759405ec541a0ac15e4771e92826b\n",
      "No such comm: 88c759405ec541a0ac15e4771e92826b\n",
      "No such comm: 88c759405ec541a0ac15e4771e92826b\n",
      "No such comm: 88c759405ec541a0ac15e4771e92826b\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\", \"orange\", \"purple\"]\n",
    "model_list= []\n",
    "for nlayers in nLayers_list:\n",
    "    model_ld, result_ld = train(nlayers, retrain=retrain)\n",
    "    model_list.append({\"nlayers\": nlayers,\n",
    "                       \"model\": model_ld, \n",
    "                       \"result\": result_ld, \n",
    "                       \"color\": colors.pop(0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f92a2ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'latent_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Compare loss as a function of latent dimensionality\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m latent_dims \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatent_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m nlayers \u001b[38;5;241m=\u001b[39m [m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n\u001b[1;32m      5\u001b[0m val_scores \u001b[38;5;241m=\u001b[39m [m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Compare loss as a function of latent dimensionality\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m latent_dims \u001b[38;5;241m=\u001b[39m [\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatent_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n\u001b[1;32m      4\u001b[0m nlayers \u001b[38;5;241m=\u001b[39m [m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n\u001b[1;32m      5\u001b[0m val_scores \u001b[38;5;241m=\u001b[39m [m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model_list]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'latent_dim'"
     ]
    }
   ],
   "source": [
    " #Compare loss as a function of latent dimensionality\n",
    "\n",
    "latent_dims = [m[\"latent_dim\"] for m in model_list]\n",
    "nlayers = [m[\"nlayers\"] for m in model_list]\n",
    "val_scores = [m[\"result\"][\"val\"][0][\"test_loss\"] for m in model_list]\n",
    "colors = [m[\"color\"] for m in model_list]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "axes[0].scatter(latent_dims, val_scores, color=colors, marker=\"*\", s=100)\n",
    "axes[0].set_xlabel(\"Latent Dimensionality\")\n",
    "axes[0].set_ylabel(\"Validation Loss\")\n",
    "\n",
    "axes[1].scatter(nlayers, val_scores, color=colors, marker=\"*\", s=100)\n",
    "axes[1].set_xlabel(\"Number of Layers\")\n",
    "axes[1].set_ylabel(\"Validation Loss\")\n",
    "\n",
    "# Scatter plot with latent_dim on x-axis, nlayers on y-axis, and colormap on z-axis (val_scores)\n",
    "scatter = axes[2].scatter(latent_dims, nlayers, c=val_scores, cmap='viridis', marker=\"s\", s=600)\n",
    "axes[2].set_xlabel(\"Latent Dimensionality\")\n",
    "axes[2].set_ylabel(\"Number of Layers\")\n",
    "axes[2].set_title(\"Validation Loss\")\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(scatter, ax=axes[2])\n",
    "cbar.set_label(\"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18310b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define plot functions\n",
    "\n",
    "def plot(inTensor, axes, color, dim, label, linestyle=\"--\", skip=0):\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i >= len(inTensor)+skip:\n",
    "            break\n",
    "        if i < skip:\n",
    "            continue    \n",
    "        ax.plot(inTensor[i-skip][0][dim].numpy(), linestyle, color=color, label=label)\n",
    "        ax.legend()\n",
    "\n",
    "def reconstruct_signals(input_signal, model_l, axes, dim):\n",
    "    # Reconstruct images\n",
    "    model = model_l[\"model\"].eval()\n",
    "    color = model_l[\"color\"]\n",
    "    label = \"ld %s nl %s\" % (model_l[\"latent_dim\"], model_l[\"nlayers\"])\n",
    "    with torch.no_grad():\n",
    "        reconst_imgs = model(input_signal[0].to(model.device), input_signal[1].to(model.device))    \n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "    plot(reconst_imgs, axes, color, dim, label)\n",
    "\n",
    "def generate_signals(input_latents, model_l, axes, dim, skip=0, color=\"b\"):\n",
    "    # Reconstruct images\n",
    "    model = model_l[\"model\"].eval()\n",
    "    label = \"e=%.1f, x=%.1f, y=%.1f\" % (input_latents[1][0][0].numpy(), input_latents[0][0][0].numpy(), input_latents[0][0][1].numpy())\n",
    "    with torch.no_grad():\n",
    "        reconst_imgs = model.decoder(input_latents[0].to(model.device), input_latents[1].to(model.device))    \n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "    plot(reconst_imgs, axes, color, dim, label, skip=skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the reconstructions with different model hyper-parameters\n",
    "ncols = 4\n",
    "nrows = 16\n",
    "dim = 0\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(15, 40))\n",
    "input_imgs = get_train_images(ncols*nrows)\n",
    "#input_imgs = get_validation_images(ncols*nrows)\n",
    "\n",
    "for m in model_list:\n",
    "    reconstruct_signals(input_imgs, m, axes, dim)\n",
    "plot(input_imgs[0], axes, \"black\", dim=dim, label=\"input\", linestyle=\"-\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af705ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the latent space\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import ipywidgets as widgets\n",
    "    \n",
    "# Create the slider\n",
    "ene_slider = widgets.FloatSlider(value=0.5, min=0, max=1, step=0.01, description='Energy:')\n",
    "nch = get_train_images(1)[1].shape[1] - 1\n",
    "ch_dropdown = widgets.Dropdown(\n",
    "    options=[(f'Channel {i}', i) for i in range(-1,nch+1)],\n",
    "    value=0,\n",
    "    description='Channel:',\n",
    ")\n",
    "# Display the slider\n",
    "display(ch_dropdown)\n",
    "display(ene_slider)\n",
    "\n",
    "idx_test = 0\n",
    "\n",
    "def get_histo(idx_ch):\n",
    "    with torch.no_grad():\n",
    "        model_list[idx_test][\"model\"].eval()\n",
    "        dataset = get_train_images(500_000)\n",
    "        # Filter the dataset\n",
    "        if idx_ch >= 0:\n",
    "            dataset = (dataset[0][dataset[1][:, idx_ch+1] == 1], \n",
    "                       dataset[1][dataset[1][:, idx_ch+1] == 1])\n",
    "        avg_id = dataset[1].mean(dim=0)\n",
    "\n",
    "        \n",
    "\n",
    "        histoOut = torch.histogramdd(   model_list[idx_test][\"model\"].forward(dataset[0].to(model_list[idx_test][\"model\"].device)),\n",
    "                                        bins=5_000,\n",
    "                                        range = None,\n",
    "                                        )\n",
    "        histoOut[0].detach().numpy()\n",
    "\n",
    "        return [histoOut, avg_id]\n",
    "\n",
    "\n",
    "#Create the 2 canvases\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "                \n",
    "def on_ch_dropdown_change(change):\n",
    "    value = change['new']\n",
    "    histo, avg_id = get_histo(value)\n",
    "\n",
    "    colors=[\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\", \"orange\", \"purple\", \"brown\", \"pink\", \"olive\", \"cyan\"]\n",
    "\n",
    "    axes[0].imshow( histo[0], \n",
    "                    extent=[histo[1][0][0], \n",
    "                            histo[1][0][-1],\n",
    "                            histo[1][1][0], \n",
    "                            histo[1][1][-1]], \n",
    "                    aspect='auto', \n",
    "                    origin='lower', \n",
    "                    norm=matplotlib.colors.LogNorm())\n",
    "                    \n",
    "    def on_histo_double_click(event):\n",
    "        if event.dblclick:\n",
    "            x = event.xdata\n",
    "            y = event.ydata\n",
    "            if x is not None and y is not None:\n",
    "\n",
    "                #Get coordinates\n",
    "                last_click = [x, y] \n",
    "                print(\"[%.2f, %.2f]\" % (x, y))\n",
    "\n",
    "                color=colors.pop(0)\n",
    "                #Annote in the plot\n",
    "                axes[0].annotate(\"[%.2f, %.2f]\" % (x, y), (x, y), color=color, bbox=dict(facecolor='white', edgecolor='white', alpha=0.5))\n",
    "                axes[0].plot(x, y, 'o', color=color)\n",
    "\n",
    "                #Plot the signal\n",
    "                def on_ene_slider_change(change):\n",
    "                    value = change['new']\n",
    "                    double_click_tensor = torch.FloatTensor([last_click])\n",
    "                    id_tensor = avg_id.unsqueeze(0).repeat(double_click_tensor.size(0), 1)\n",
    "                    id_tensor[:, 0] = value\n",
    "                    generate_signals([double_click_tensor, id_tensor], model_list[idx_test], axes, dim=0, skip=1, color=color)\n",
    "\n",
    "                ene_slider.observe(on_ene_slider_change, names='value')\n",
    "\n",
    "    fig.canvas.mpl_connect('button_press_event', on_histo_double_click)\n",
    "\n",
    "ch_dropdown.observe(on_ch_dropdown_change, names='value')            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding similar signals in the latent space and then checking the signals\n",
    "\n",
    "def embed_imgs(model, data_loader):\n",
    "    # Encode all images in the data_laoder using model, and return both images and encodings\n",
    "    img_list, embed_list = [], []\n",
    "    model.eval()\n",
    "    for imgs, ids in data_loader:\n",
    "        with torch.no_grad():\n",
    "            z = model.encoder(imgs.to(model.device), ids.to(model.device))\n",
    "        img_list.append(imgs)\n",
    "        embed_list.append(z)\n",
    "    return (torch.cat(img_list, dim=0), torch.cat(embed_list, dim=0))\n",
    "\n",
    "\n",
    "train_img_embeds = embed_imgs(model_list[idx_test][\"model\"], train_loader)\n",
    "test_img_embeds = embed_imgs(model_list[idx_test][\"model\"], test_loader)\n",
    "\n",
    "def find_similar_images(query_img, query_z, key_embeds, ax, K=8, dim=0):\n",
    "    # Find closest K images. We use the euclidean distance here but other like cosine distance can also be used.\n",
    "    dist = torch.cdist(query_z[None, :], key_embeds[1], p=2)\n",
    "    dist = dist.squeeze(dim=0)\n",
    "    dist, indices = torch.sort(dist)\n",
    "    # Plot K closest images\n",
    "    imgs_to_display = torch.cat([query_img[None], key_embeds[0][indices[:K]]], dim=0)\n",
    "    #grid = torchvision.utils.make_grid(imgs_to_display, nrow=K + 1, normalize=True, value_range=(-1, 1))\n",
    "    #grid = grid.permute(1, 2, 0)\n",
    "    #plt.figure(figsize=(12, 3))\n",
    "    #plt.imshow(grid)\n",
    "    #plt.axis(\"off\")\n",
    "    #plt.show()\n",
    "    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\", \"orange\", \"purple\", \"brown\", \"pink\"]\n",
    "    ax.plot(query_img[0][dim].numpy(), color=\"k\", label=\"query\")\n",
    "    for i in range(imgs_to_display.size()[0]):\n",
    "        ax.plot(imgs_to_display[i][0][dim].numpy(), \"--\", color=colors.pop(0), label=\"latent_dim %i\" % latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the closest images for the first N test images as example\n",
    "ncols = 6\n",
    "nrows = 6\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    find_similar_images(test_img_embeds[0][i], test_img_embeds[1][i], key_embeds=train_img_embeds, K=6, ax=ax, dim=0)\n",
    "\n",
    "#This does not make sense, i probabily did something wrong"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
